#VP Method
import tensorflow as tf
import numpy as np

# Define the PINN architecture
class PINN(tf.keras.Model):
    def __init__(self):
        super(PINN, self).__init__()
        self.dense1 = tf.keras.layers.Dense(32, activation='tanh')
        self.dense2 = tf.keras.layers.Dense(32, activation='tanh')
        self.dense3 = tf.keras.layers.Dense(32, activation='tanh')
        self.dense4 = tf.keras.layers.Dense(1, use_bias = False)  # Output for pressure
        self.dense5 = tf.keras.layers.Dense(1, use_bias=False)  # Output for u
        self.dense6 = tf.keras.layers.Dense(1, use_bias=False)  # Output for v

    def call(self, inputs):
        x = self.dense1(inputs)
        x = self.dense2(x)
        x = self.dense3(x)
        p = self.dense4(x)  # Pressure
        u = self.dense5(x)  # Velocity component u
        v = self.dense6(x)  # Velocity component v
        return p, u, v

# Define the loss function
def loss_function(p, u, v, grads_p, grads_u, grads_v, grads_u_u, grads_v_v, rho, mu):
    # Cast tensors to float32
    grads_p = tf.cast(grads_p, tf.float32)
    grads_u = tf.cast(grads_u, tf.float32)
    grads_v = tf.cast(grads_v, tf.float32)
    grads_u_u = tf.cast(grads_u_u, tf.float32)
    grads_v_v = tf.cast(grads_v_v, tf.float32)

    # Compute residuals
    r_u = u * grads_u[:, 0] + v * grads_u[:, 1] + (1.0 / rho) * grads_p[:, 0] - \
          mu / rho * (grads_u_u[:, 0] + grads_u_u[:, 1])
    r_v = u * grads_v[:, 0] + v * grads_v[:, 1] + (1.0 / rho) * grads_p[:, 1] - \
          mu / rho * (grads_v_v[:, 0] + grads_v_v[:, 1])

    # Compute loss
    loss_u = tf.reduce_mean(tf.square(r_u))
    loss_v = tf.reduce_mean(tf.square(r_v))

    uv_pred_bc = np.vstack((u_pred[:num_boundary_points//2], u_pred[-num_boundary_points//2:], v_pred[:num_boundary_points//2], v_pred[-num_boundary_points//2:]))

    r_bc = uv_pred_bc - boundary_conditions_uv

    loss_bc = tf.reduce_mean(tf.square(r_bc))
    loss_bc = tf.cast(loss_bc, tf.float32)

    return loss_u + loss_v + loss_bc

# Generate training data (sample points)
# You need to generate your training data according to your problem setup
h = 0.41  # Height of the domain
w = 2.1 #Width of the domain
num_points = 1000  # Total number of training points
num_boundary_points = 100  # Number of points along the boundary

# Generate points within the domain
y_interior = np.random.uniform(low=0.01*h, high=0.99*h, size=(num_points-num_boundary_points, 1))

# Generate points along the boundary
y_boundary = np.linspace(0, h, num_boundary_points).reshape(-1, 1)

# Combine interior and boundary points
training_data_y = np.vstack((y_interior, y_boundary))

# Fluid properties for air at standard conditions
rho = 1.225  # Density in kg/m^3
mu = 1.81e-5  # Dynamic viscosity in Pa.s

# Inlet velocity profile
U_max = 2.0  # Maximum velocity
U_inlet = (2/3) * U_max  # Inlet velocity

# Boundary conditions
'''
u_bc_inlet = 4 * U_max * (1 - (y_boundary / h)) * (y_boundary / h)
u_bc_outlet = np.zeros((num_boundary_points, 1))  # Assuming no-slip condition at outlet
'''
# Wall boundary condition
u_bc_wall = np.zeros((num_boundary_points, 1))
v_bc_wall = np.zeros((num_boundary_points, 1))

# Concatenate boundary condition data for velocity components
boundary_conditions_uv = np.vstack((u_bc_wall, v_bc_wall))

# Concatenate all boundary conditions
boundary_conditions_all = np.vstack((boundary_conditions_uv, np.vstack((u_bc_inlet, u_bc_outlet))))

# Concatenate x and y coordinates for training data
training_data_x = np.reshape(np.linspace(0,w,num_points+num_boundary_points),(num_points + num_boundary_points, 1))
training_data_y_all = np.vstack((training_data_y, y_boundary))
training_data = np.hstack((training_data_x, training_data_y_all))

# Create PINN model
model = PINN()

# Define optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

# Training loop
epochs = 1000
for epoch in range(epochs):
    with tf.GradientTape(persistent=True) as tape:
        # Forward pass
        inputs = tf.convert_to_tensor(training_data, dtype=tf.float32)  # Replace with your training data
        tape.watch(inputs)
        p_pred, u_pred, v_pred = model(inputs)

        # Compute gradients
        grads_p = tape.gradient(p_pred, inputs)
        grads_u = tape.gradient(u_pred, inputs)
        grads_v = tape.gradient(v_pred, inputs)

        # Compute second derivatives
        grads_u_u = tape.gradient(grads_u, inputs)
        grads_v_v = tape.gradient(grads_v, inputs)

        # Compute loss
        total_loss = loss_function(p_pred, u_pred, v_pred, grads_p, grads_u, grads_v, grads_u_u, grads_v_v, rho, mu)

    # Compute gradients
    gradients = tape.gradient(total_loss, model.trainable_variables)

    # Update weights
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    if (epoch+1) % 50 == 0:
        print(f'Epoch {epoch+1}, Total Loss: {total_loss.numpy()}, '
            f'Loss_u: {loss_u.numpy()}, Loss_v: {loss_v.numpy()}')
